# ANN Model for Hybrid Nanofluid Boundary Layer Flow

## Overview

This project implements a **traditional Artificial Neural Network (ANN)** trained with the **Levenberg-Marquardt algorithm** to predict the flow and thermal characteristics of hybrid nanofluids over a stretching sheet. The model is trained on ground-truth numerical data generated by solving coupled nonlinear ODEs.

**Key Features:**
- ✅ Pure data-driven ANN (not PINN)
- ✅ 9 hidden layers × 30 neurons with tanh activation
- ✅ Levenberg-Marquardt optimization
- ✅ Numerical ODE solver using scipy.integrate.solve_bvp
- ✅ Comprehensive validation with 8+ error metrics
- ✅ Manuscript-style visualization

---

## Project Structure

```
ANN-net/
├── docs/                      # All documentation
│   ├── README.md              # This file
│   ├── ARCHITECTURE.md        # Technical details
│   ├── USAGE.md               # Usage guide
│   └── MANUSCRIPT.docx        # Research manuscript
├── src/                       # All source code
│   ├── config.py              # Central configuration
│   ├── main.py                # Main entry point
│   ├── generate_data.py       # Dataset generation
│   ├── data_loader.py         # Data loading
│   ├── trainer.py             # Training pipeline
│   ├── visualizer.py          # Visualization
│   ├── validate_model.py      # Model validation
│   ├── models/
│   │   ├── __init__.py
│   │   ├── ann.py             # ANN architecture
│   │   └── lm_optimizer.py    # LM optimizer
│   └── solver/
│       ├── __init__.py
│       └── ode_solver.py      # ODE solver
├── data/                      # Generated datasets
├── outputs/                   # All outputs
│   ├── models/                # Trained models
│   └── plots/                 # Generated plots
├── .gitignore
├── requirements.txt
└── README.md                  # Quick reference
```

---

## Installation

### Prerequisites
- Python 3.10 or higher
- pip package manager

### Setup

```bash
# Navigate to project directory
git clone https://github.com/emonmorol/ANN-hybrid-nanofluid-model.git

# Install dependencies
pip install -r requirements.txt
```

**Required packages:**
- torch >= 2.0.0
- numpy >= 1.24.0
- scipy >= 1.10.0
- matplotlib >= 3.7.0
- pandas >= 2.0.0
- tqdm >= 4.65.0
- scikit-learn >= 1.3.0

---

## Quick Start

### Complete Workflow

```bash
# Generate training data
python src/main.py generate

# Train the model
python src/main.py train

# Validate the model
python src/validate_model.py

# Or run everything at once
python src/main.py all
```

### Individual Scripts

```bash
# Generate dataset only
python src/generate_data.py

# Train with custom settings (edit src/config.py first)
python src/main.py train

# Clean generated files
python src/main.py clean
```

---

## Physical Model

### Governing Equations

**Momentum Equation (Eq. 8):**
```
(ν_hnf/ν_f) f''' + f·f'' + (2n)/(n+1)·(1 - f'^2) - 2/(n+1)·(σ_hnf/σ_f)·(ρ_f/ρ_hnf)·M·(f' - 1) = 0
```

**Energy Equation (Eq. 9):**
```
(κ_hnf/κ_f + Nr/(1 + (Tr-1)θ)^3)·θ'' + Pr·As·(f·θ' - 2(2n-1)/(n+1)·f'·θ) 
  + 3·Nr·(Tr-1)/(1 + (Tr-1)θ)^2·(θ')^2 = 0
```

**Boundary Conditions (Eq. 10):**
```
At η = 0:
  f(0) = 0
  f'(0) = 1 + β·f''(0)
  θ'(0) = -Nh·(1 - θ(0))

At η → ∞:
  f'(∞) → 1
  θ(∞) → 0
```

### Parameters

| Symbol | Description | Range |
|--------|-------------|-------|
| M | Magnetic parameter | [0.1, 3.0] |
| Nr | Radiation parameter | [0.1, 1.5] |
| Nh | Convective heat transfer parameter | [0.1, 1.5] |
| λ | Stretching parameter | [0.1, 2.5] |
| β | Velocity slip parameter | [0.1, 0.3] |
| Pr | Prandtl number | 6.2 (water-based) |
| n | Power-law index | 1.0 |
| Tr | Temperature ratio | 1.5 |
| As | Unsteadiness parameter | 1.0 |

### Engineering Quantities

- **Skin Friction Coefficient:** `Cf = f''(0)`
- **Nusselt Number:** `Nu = -θ'(0)`

---

## Model Architecture

### ANN Structure

```
Input Layer:     1 neuron  (η)
                 ↓
Hidden Layer 1:  30 neurons (tanh)
Hidden Layer 2:  30 neurons (tanh)
...
Hidden Layer 9:  30 neurons (tanh)
                 ↓
Output Layer:    2 neurons  (f, θ)
```

**Total Parameters:** ~8,732  
**Initialization:** Xavier uniform  
**Activation:** Hyperbolic tangent (tanh)

### Levenberg-Marquardt Optimization

The LM algorithm combines gradient descent and Gauss-Newton methods:

**Update Rule:**
```
(J^T·J + λ·I)·Δp = -J^T·r

where:
  J = Jacobian matrix
  r = residuals (predictions - targets)
  λ = damping parameter (adaptive)
  Δp = parameter update
```

**Adaptive Damping:**
- Successful step → λ = λ × 0.1 (move toward Gauss-Newton)
- Failed step → λ = λ × 10 (move toward gradient descent)

---

## Model Validation

### Validation Methodology

The ANN is validated by comparing predictions against numerical solutions from `scipy.integrate.solve_bvp`.

### Error Metrics

| Metric | Formula | Target |
|--------|---------|--------|
| **MSE** | Mean Squared Error | < 1e-6 |
| **RMSE** | Root MSE | < 1e-3 |
| **MAE** | Mean Absolute Error | < 1e-4 |
| **Max Error** | Maximum absolute error | < 1e-3 |
| **R²** | Coefficient of determination | > 0.9999 |
| **Relative Error** | Percentage error | < 0.01% |

### Running Validation

```bash
python src/validate_model.py
```

**Outputs:**
- Console metrics for f(η) and θ(η)
- Validation plots: `outputs/plots/validation_single_case.png`
- Summary table: `outputs/plots/validation_summary.csv` (manuscript-ready)

### Validation Plots Include:

1. **Comparison Plots**: Numerical vs. ANN predictions
2. **Error Plots**: Absolute errors on log scale
3. **Scatter Plots**: Predicted vs. actual with R²
4. **Error Distribution**: Histogram of errors
5. **Metrics Table**: Comprehensive summary

### Expected Results

For a well-trained model:

```
--- f(η) Metrics ---
  MSE                      : 2.35e-08
  MAE                      : 1.12e-04
  R_squared                : 0.999998
  Correlation              : 0.999999

--- θ(η) Metrics ---
  MSE                      : 1.23e-09
  MAE                      : 2.35e-05
  R_squared                : 0.999999
  Correlation              : 0.999999
```

### Custom Validation

```python
import sys
from pathlib import Path
sys.path.insert(0, 'e:/University/FYDP/ANN-net')

from src.validate_model import ModelValidator

validator = ModelValidator(
    model_path="outputs/models/best_model.pth",
    scaler_dir="outputs/models"
)

# Validate specific case
custom_params = {
    'M': 1.5, 'Nr': 0.8, 'Nh': 0.6, 'lam': 1.2,
    'beta': 0.1, 'Pr': 6.2, 'n': 1.0, 'Tr': 1.5, 'As': 1.0,
    'eta_max': 10.0, 'n_points': 400
}

result = validator.validate_single_case(custom_params, verbose=True)
validator.plot_validation_results(result, save_path="my_validation.png")

# Validate multiple cases
test_cases = [
    {**custom_params, 'M': 0.5},
    {**custom_params, 'M': 1.0},
    {**custom_params, 'M': 1.5},
]

summary_df = validator.validate_multiple_cases(test_cases)
summary_df.to_csv("my_validation_summary.csv")
```

---

## Configuration

Edit `src/config.py` to customize:

### Data Generation
```python
PARAM_RANGES = {
    'M': [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0],
    'Nr': [0.1, 0.3, 0.5, 0.7, 1.0, 1.5],
    # ... add more parameter ranges
}

ETA_MAX = 10.0
N_POINTS = 400
```

### Model Architecture
```python
MODEL_PARAMS = {
    'input_dim': 1,
    'hidden_dim': 30,
    'num_hidden_layers': 9,
    'output_dim': 2,
    'activation': 'tanh'
}
```

### Training Settings
```python
TRAIN_PARAMS = {
    'epochs': 100,
    'batch_size': 'full',  # or integer
    'learning_rate': 1.0,
    'optimizer': 'lbfgs',  # 'lbfgs', 'adam', 'lm_custom'
    'early_stopping_patience': 20,
}
```

---

## Troubleshooting

### ODE Solver Fails
```
Solution: Adjust initial guess or increase max_nodes
File: src/solver/ode_solver.py, line 120
```

### Training Loss Not Decreasing
```
Solution: 
- Check data normalization
- Reduce learning rate
- Increase max_nfev in scipy optimizer
```

### Memory Error
```
Solution: Reduce batch_size in src/config.py
Current: 'full' → Try: 1000 or 500
```

### High Validation Errors
```
Solution:
- Retrain with more epochs
- Check if test parameters are within training range
- Increase training data diversity
```

---

## Citation

If you use this code, please cite the manuscript:

```
[Manuscript citation to be added]
```

---

## License

This project is for academic and research purposes.

---

## Acknowledgments

- Numerical solver: scipy.integrate.solve_bvp
- Deep learning framework: PyTorch
- Optimization: Levenberg-Marquardt algorithm

---

**Last Updated:** 2025-11-23  
**Version:** 2.0.0  
**Status:** ✅ Complete and tested
